{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment B (Group A): \n",
    "* In this assignment, you will first learn how the word permutations and misspelled words in evaluation datasets can decrease the evaluation accuracy of models of different types.\n",
    "* You will also learn how fine-tuning one of them on a training dataset that also contains random word permutations and misspelled words can increase its evaluation accuracy. \n",
    "* Finally, you will be asked to increase the other model's evaluation accuracy over a threshold **as quickly as possible**, based on the provided information.\n",
    "* This notebook walks you through this process step-by-step. Run each cell of code and read the text instructions untill you read section 6 where you need to write your own code for the task.\n",
    "* If you have any question during the assignment, please ask the instructor directly. It is prohibited to consult with any generative language models, e.g. ChatGPT, about this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You are given up to 40 minutes to finish this assignment. Let the instructor start timing when you read this sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Library Import  (run the code, no need to read through it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "os.environ['HF_HOME'] = '/workspace/HF_cache/'\n",
    "os.environ['HF_DATASETS_CACHE'] = '/workspace/HF_cache/datasets'\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/workspace/HF_cache/transformers_cache/'\n",
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "import torch\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import transformers\n",
    "import datasets\n",
    "from transformers import AutoTokenizer, AutoConfig, TrainingArguments, Trainer\n",
    "from user_functions_group_A import set_dataset_logging_level\n",
    "import logging\n",
    "set_dataset_logging_level(logging.ERROR, [\"datasets\"])\n",
    "!chmod -R 777 .\n",
    "!rm -rf tmp_*\n",
    "!rm -rf models/*_versioned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Datasets\n",
    "\n",
    "* There are seven datasets under ```datasests``` that we used to train (with suffix ```_train```) and ```evaluate``` (with suffix ```_eval```) language models in this assignment. You can display the datasets by running ```!ls datasets``` later.\n",
    "```\n",
    "    mlm_eval\t      mlm_shifted_train     sst2_eval\t\t    sst2_train\n",
    "    mlm_shifted_eval  mlm_train\t         sst2_shifted_eval\n",
    "```\n",
    "* Prefix ```mlm``` in the names indicates that the dataset is used for models performing the pre-training task, i.e. masked language modeling, and Prefix ```sst2``` in the names indicates that the dataset is used for models performing the downstream task, i.e. sequence classification.\n",
    "* ```_shifted_``` in the names indicates that the dataset contains random permutation of word order and misspelled words altered from a corresponding dataset, i.e. ```sst2_shifted_eval``` is altered from ```sst2_eval```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. An Example of Random Permutation of Word Order and Misspelled Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a comparison bewteen two inputs from dataset ```mlm_eval``` and ```mlm_shifted_eval```: \n",
    "* ```their``` in the second sentence is misspelled as ```thwir```.\n",
    "* The words in the last sentence are randomly permutated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \" Troops are divided into five classes : Scouts , Shocktroopers , Engineers , Lancers and Armored Soldier . Troopers can switch classes by changing their assigned weapon . Changing class does not greatly affect the stats gained while in a previous class . With victory in battle , experience points are awarded to the squad , which are distributed into five different attributes shared by the entire squad , a feature differing from early games ' method of distributing to different unit types . \\n\"}\n"
     ]
    }
   ],
   "source": [
    "print(datasets.load_from_disk('datasets/mlm_eval')[11]) #load dataset from path and display the 11th item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"Troops are divided into five classes : Scouts , Shocktroopers , Engineers , Lancers and Armored Soldier . Troopers can switch classes by changing thwir assigned weapon . Changing class does not greatly affect the stats gained while in a previous class . With victory in battle , experience points are awarded to the squad , which are distributed into five different atributes shared by distributing method feature unit , early games entire the squad of different types to a from differing ' . \"}\n"
     ]
    }
   ],
   "source": [
    "print(datasets.load_from_disk('datasets/mlm_shifted_eval')[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Models\n",
    "\n",
    "There are ```three``` models under the directory ```models``` where you can display them by running ```!ls models``` later.\n",
    "```\n",
    "    distilbert  distilbert_v2  distilbert-sentiment\n",
    "```\n",
    "* Among the models,  ```models/distilbert_v2``` and ```models/distilbert-sentiment``` are derived from ```models/distilbert```.\n",
    "* Specifically, ```models/distilbert-sentiment``` is adapted from ```models/distilbert``` and is trained on dataset ```sst2_train``` to perform a downstream task, i.e. sequence classification.\n",
    "* ```models/distilbert_v2``` is the next version of ```models/distilbert``` via fine-tuning and they perform the same pre-training task, i.e.  masked language modeling. We will introduce more details about this model under block 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model Accuracy Drop due to Random Permutation of Word Order and Misspelled Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When ```distilbert``` and ```distilbert-sentiment``` were evaluated on datasets ```mlm_eval``` and ```sst2_eval``` that do not contain random permutation of word order and misspelled words, the evaluation accuracy for the two models are ```0.505``` and ```0.905``` respectively. However, when they were evaluated on datasets ```mlm_shifted_eval``` and ```sst2_shifted_eval```, you can see the evaluation accuracy drops to ```0.307``` and ```0.825``` respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your colleague noticed the decrease and created a dataset ```mlm_shifted_train``` to fine-tune ```distilbert``` and produced ```distilbert_v2``` by using transformers.Trainer. And ```distilbert_v2```'s evaluation accuracy on ```mlm_shifted_eval``` is increased to ```0.382```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is the comparison between inputs from mlm_train and mlm_shifted_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ' = = In the Union Navy = = \\n'}\n",
      "{'text': '= In Unoon Navy = ther = = '}\n"
     ]
    }
   ],
   "source": [
    "print(datasets.load_from_disk('datasets/mlm_train')[1])\n",
    "print(datasets.load_from_disk('datasets/mlm_shifted_train')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we evaluate the aforementioned models and show their accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load models and tokenizers\n",
    "model_path = \"models/distilbert\"\n",
    "tokenizer1 = AutoTokenizer.from_pretrained(model_path)\n",
    "architecture = AutoConfig.from_pretrained(model_path).architectures[0]\n",
    "model1 = getattr(transformers, architecture).from_pretrained(model_path)\n",
    " \n",
    "model_path = \"models/distilbert-sentiment\"\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(model_path)\n",
    "architecture = AutoConfig.from_pretrained(model_path).architectures[0]\n",
    "model2 = getattr(transformers, architecture).from_pretrained(model_path)\n",
    "\n",
    "model_path = \"models/distilbert_v2\"\n",
    "tokenizer3 = AutoTokenizer.from_pretrained(model_path)\n",
    "architecture = AutoConfig.from_pretrained(model_path).architectures[0]\n",
    "model3 = getattr(transformers, architecture).from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we import some functions for model evaluation\n",
    "from user_functions_group_A import evaluate, mlm_preprocess_function, compute_metrics_mlm, glue_preprocess_function, compute_metrics_glue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert's accuracy on mlm_eval: {'eval_accuracy': '0.505'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert's accuracy on mlm_shifted_eval: {'eval_accuracy': '0.307'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert-sentiment's accuracy on sst2_eval: {'eval_accuracy': '0.905'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert-sentiment's accuracy on sst2_shifted_eval: {'eval_accuracy': '0.825'}\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert_v2's accuracy on mlm_shifted_eva:l {'eval_accuracy': '0.382'}\n"
     ]
    }
   ],
   "source": [
    "# Remeber to apply preprocessing functions on dataset before train/eval\n",
    "eval_dataset = mlm_preprocess_function(datasets.load_from_disk('datasets/mlm_eval'), tokenizer1)\n",
    "print('distilbert\\'s accuracy on mlm_eval:',evaluate(model1.eval(), tokenizer1, eval_dataset, compute_metrics_mlm))\n",
    "\n",
    "eval_dataset = mlm_preprocess_function(datasets.load_from_disk('datasets/mlm_shifted_eval'), tokenizer1)\n",
    "print('distilbert\\'s accuracy on mlm_shifted_eval:',evaluate(model1.eval(), tokenizer1, eval_dataset, compute_metrics_mlm))\n",
    "\n",
    "model1 = model1.cpu() # move models back to cpu. It's a good practice to unload idle model from gpu to save memory for other models\n",
    "\n",
    "eval_dataset = glue_preprocess_function(datasets.load_from_disk('datasets/sst2_eval'), tokenizer2)\n",
    "print('distilbert-sentiment\\'s accuracy on sst2_eval:',evaluate(model2.eval(), tokenizer2, eval_dataset, compute_metrics_glue))\n",
    "\n",
    "eval_dataset = glue_preprocess_function(datasets.load_from_disk('datasets/sst2_shifted_eval'), tokenizer2)\n",
    "print('distilbert-sentiment\\'s accuracy on sst2_shifted_eval:',evaluate(model2.eval(), tokenizer2, eval_dataset, compute_metrics_glue))\n",
    "\n",
    "model2 = model2.cpu()\n",
    "\n",
    "eval_dataset = mlm_preprocess_function(datasets.load_from_disk('datasets/mlm_shifted_eval'), tokenizer3)\n",
    "print(type(eval_dataset))\n",
    "print('distilbert_v2\\'s accuracy on mlm_shifted_eva:l',evaluate(model3.eval(), tokenizer3, eval_dataset, compute_metrics_mlm))\n",
    "\n",
    "model3 = model3.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*\\*Note: ```distilbert_v2``` is a new version of ```distilbert``` that has higher accuracy on ```mlm_shifted_eval```**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. It's Your Turn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now its your turn to create a new version of ```distilbert-sentiment``` and increase its accuracy on ```sst2_shifted_eval``` by at least 1\\%, i.e., from 0.825 to 0.835, **as quickly as possible** (let the instructor know if you finish so he can stop timing)\n",
    "* You may refer back to the tutorial for API usage.\n",
    "* Don't use any ```eval``` dataset for training.\n",
    "* #### Let the instructor know when you read this sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
