{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment B (Group B): \n",
    "* In this assignment, you will first learn how the word permutations and misspelled words in evaluation datasets can decrease the evaluation accuracy of models of different types.\n",
    "* You will also learn how fine-tuning one of them on a training dataset that also contains random word permutations and misspelled words can increase its evaluation accuracy. \n",
    "* Finally, you will be asked to increase the other model's evaluation accuracy over a threshold **as quickly as possible**, based on the provided information.\n",
    "* This notebook walks you through this process step-by-step. Run each cell of code and read the text instructions untill you read section 6 where you need to write your own code for the task.\n",
    "* If you have any question during the assignment, please ask the instructor directly. It is prohibited to consult with any generative language models, e.g. ChatGPT, about this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You are given up to 40 minutes to finish this assignment. Let the instructor start timing when you read this sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Library Import  (run the code, no need to read through it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "os.environ['HF_HOME'] = '/workspace/HF_cache/'\n",
    "os.environ['HF_DATASETS_CACHE'] = '/workspace/HF_cache/datasets'\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/workspace/HF_cache/transformers_cache/'\n",
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "import torch\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import datasets\n",
    "from user_functions_group_B import set_dataset_logging_level\n",
    "import logging\n",
    "set_dataset_logging_level(logging.ERROR, [\"datasets\"])\n",
    "!chmod -R 777 .\n",
    "!rm -rf tmp_*\n",
    "!rm -rf *.html\n",
    "!rm -rf *.pdf\n",
    "!rm -rf models/*_versioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "MGIT_PATH=os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "sys.path.append(MGIT_PATH)\n",
    "from utils.lineage.graph import *\n",
    "from utils import meta_functions\n",
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Datasets\n",
    "\n",
    "* There are seven datasets under ```datasests``` that we used to train (with suffix ```_train```) and ```evaluate``` (with suffix ```_eval```) language models in this assignment. You can display the datasets by running ```!ls datasets``` later.\n",
    "```\n",
    "    mlm_eval\t      mlm_shifted_train     sst2_eval\t\t    sst2_train\n",
    "    mlm_shifted_eval  mlm_train\t         sst2_shifted_eval\n",
    "```\n",
    "* Prefix ```mlm``` in the names indicates that the dataset is used for models performing the pre-training task, i.e. masked language modeling, and Prefix ```sst2``` in the names indicates that the dataset is used for models performing the downstream task, i.e. sequence classification.\n",
    "* ```_shifted_``` in the names indicates that the dataset contains random permutation of word order and misspelled words altered from a corresponding dataset, i.e. ```sst2_shifted_eval``` is altered from ```sst2_eval```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. An Example of Random Permutation of Word Order and Misspelled Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a comparison bewteen two inputs from dataset ```mlm_eval``` and ```mlm_shifted_eval```: \n",
    "* ```their``` in the second sentence is misspelled as ```thwir```.\n",
    "* The words in the last sentence are randomly permuted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \" Troops are divided into five classes : Scouts , Shocktroopers , Engineers , Lancers and Armored Soldier . Troopers can switch classes by changing their assigned weapon . Changing class does not greatly affect the stats gained while in a previous class . With victory in battle , experience points are awarded to the squad , which are distributed into five different attributes shared by the entire squad , a feature differing from early games ' method of distributing to different unit types . \\n\"}\n"
     ]
    }
   ],
   "source": [
    "print(datasets.load_from_disk('datasets/mlm_eval')[11]) #load dataset from path and display the 11th item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"Troops are divided into five classes : Scouts , Shocktroopers , Engineers , Lancers and Armored Soldier . Troopers can switch classes by changing thwir assigned weapon . Changing class does not greatly affect the stats gained while in a previous class . With victory in battle , experience points are awarded to the squad , which are distributed into five different atributes shared by distributing method feature unit , early games entire the squad of different types to a from differing ' . \"}\n"
     ]
    }
   ],
   "source": [
    "print(datasets.load_from_disk('datasets/mlm_shifted_eval')[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Models\n",
    "\n",
    "There are ```three``` models under the directory ```models``` where you can display them by running ```!ls models``` later.\n",
    "```\n",
    "    distilbert  distilbert_v2  distilbert-sentiment\n",
    "```\n",
    "* Among the models,  ```models/distilbert_v2``` and ```models/distilbert-sentiment``` are derived from ```models/distilbert```.\n",
    "* Specifically, ```models/distilbert-sentiment``` is adapted from ```models/distilbert``` and is trained on dataset ```sst2_train``` to perform a downstream task, i.e. sequence classification.\n",
    "* ```models/distilbert_v2``` is the next version of ```models/distilbert``` via fine-tuning and they perform the same pre-training task, i.e.  masked language modeling. We will introduce more details about this model under block 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* By using MGit, you can view the lineage relation among the 3 models. You can zoom in to find the model names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"450\"\n",
       "            src=\"LineageGraph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f35ae17de50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = LineageGraph.load_from_file('./') # load the Lineage graph where the models are stored in\n",
    "g.show()  # output html file and pdf file that shows the lineage relations between models\n",
    "display(IFrame('LineageGraph.html', width=800, height=450)) # dispaly html file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model Accuracy Drop due to Random Permutation of Word Order and Misspelled Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When ```distilbert``` and ```distilbert-sentiment``` were evaluated on datasets ```mlm_eval``` and ```sst2_eval``` that do not contain random permutation of word order and misspelled words, the evaluation accuracy for the two models are ```0.505``` and ```0.905``` respectively. However, when they were evaluated on datasets ```mlm_shifted_eval``` and ```sst2_shifted_eval```, you can see the evaluation accuracy drops to ```0.307``` and ```0.825``` respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your colleague noticed the decrease and created a dataset ```mlm_shifted_train``` to fine-tune ```distilbert``` and produced ```distilbert_v2``` by using LineageTrain. And ```distilbert_v2```'s evaluation accuracy on ```mlm_shifted_eval``` is increased to ```0.382```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is the comparison between inputs from mlm_train and mlm_shifted_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ' = = In the Union Navy = = \\n'}\n",
      "{'text': '= In Unoon Navy = ther = = '}\n"
     ]
    }
   ],
   "source": [
    "print(datasets.load_from_disk('datasets/mlm_train')[1])\n",
    "print(datasets.load_from_disk('datasets/mlm_shifted_train')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we evaluate the aforementioned models and show their accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model: models/distilbert\n",
      "attempting load model by infering task type\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert's accuracy on mlm_eval: 0.505\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert's accuracy on mlm_shifted_eval: 0.307\n",
      "unloading models/distilbert\n",
      "loading model: models/distilbert-sentiment\n",
      "attempting load model by infering task type\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert-sentiment's accuracy on sst2_eval: 0.905\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert-sentiment's accuracy on sst2_shifted_eval: 0.825\n",
      "unloading models/distilbert-sentiment\n",
      "loading model: models/distilbert_v2\n",
      "attempting load model by infering task type\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert_v2's accuracy on mlm_shifted_eval: 0.382\n",
      "unloading models/distilbert_v2\n"
     ]
    }
   ],
   "source": [
    "# mgit alows user to run tests by its name if the test was registered\n",
    "# with the LineagGraph by calling ```node.run_test_by_name```. \n",
    "# 'mlm_accuracy' and 'sst2_accuracy' indicate the tests are running on 'datasets/mlm_eval' and 'datasets/sst2_eval'\n",
    "# 'mlm_shifted_accuracy' and 'sst2_shifted_accuracy' indicate the tests are \\\n",
    "# running on 'datasets/mlm_shifted_eval' and 'datasets/sst2_shifted_eval'\n",
    "\n",
    "name = 'models/distilbert'\n",
    "print('distilbert\\'s accuracy on mlm_eval:', \n",
    "      str( \"%.3f\" % g.get_node(name).run_test_by_name('mlm_accuracy', return_results=True)[1]['eval_accuracy']))\n",
    "print('distilbert\\'s accuracy on mlm_shifted_eval:',\n",
    "      str( \"%.3f\" % g.get_node(name).run_test_by_name('mlm_shifted_accuracy', return_results=True)[1]['eval_accuracy']))\n",
    "g.get_node(name).unload_model(save_model=False) #It's a good practice to unload idle model to save memory for other models\n",
    "\n",
    "name = 'models/distilbert-sentiment'\n",
    "print('distilbert-sentiment\\'s accuracy on sst2_eval:',\n",
    "      str( \"%.3f\" % g.get_node(name).run_test_by_name('sst2_accuracy', return_results=True)[1]['eval_accuracy']))\n",
    "print('distilbert-sentiment\\'s accuracy on sst2_shifted_eval:',\n",
    "      str( \"%.3f\" % g.get_node(name).run_test_by_name('sst2_shifted_accuracy', return_results=True)[1]['eval_accuracy']))\n",
    "g.get_node(name).unload_model(save_model=False) #It's a good practice to unload idle model to save memory for other models\n",
    "\n",
    "name = 'models/distilbert_v2'\n",
    "print('distilbert_v2\\'s accuracy on mlm_shifted_eval:',\n",
    "      str( \"%.3f\" % g.get_node(name).run_test_by_name('mlm_shifted_accuracy', return_results=True)[1]['eval_accuracy']))\n",
    "g.get_node(name).unload_model(save_model=False) #It's a good practice to unload idle model to save memory for other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+--------------+----------------------+---------------+-----------------------+\n",
      "| nodes/tests                 | mlm_accuracy | mlm_shifted_accuracy | sst2_accuracy | sst2_shifted_accuracy |\n",
      "+-----------------------------+--------------+----------------------+---------------+-----------------------+\n",
      "| models/distilbert           | 0.505        | 0.307                |               |                       |\n",
      "+-----------------------------+--------------+----------------------+---------------+-----------------------+\n",
      "| models/distilbert-sentiment |              |                      | 0.905         | 0.825                 |\n",
      "+-----------------------------+--------------+----------------------+---------------+-----------------------+\n",
      "| models/distilbert_v2        | -            | 0.382                |               |                       |\n",
      "+-----------------------------+--------------+----------------------+---------------+-----------------------+\n"
     ]
    }
   ],
   "source": [
    "_ = meta_functions.show_result_table(g, show_metrics=True) #show the evaluation results stored in lineage Graph g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*\\* Note: ```distilbert_v2``` is a new version of ```distilbert``` that has higher accuracy on ```mlm_shifted_eval``` recorded by MGit** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. It's Your Turn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now its your turn to create a new version of ```distilbert-sentiment``` and increase its accuracy on ```sst2_shifted_eval``` by at least 1\\%, i.e., from 0.825 to 0.835, **as quickly as possible** (let the instructor know if you finish so he can stop timing)\n",
    "* You may refer back to the tutorial for API usage.\n",
    "* Don't use any ```eval``` dataset for training.\n",
    "* #### Let the instructor know when you read this sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
